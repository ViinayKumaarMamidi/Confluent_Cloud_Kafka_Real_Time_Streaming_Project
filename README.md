# Confluent_Kafka_Real_Time_Streaming_Project
This repo contains details about leveraging the Confluent Cloud Kafka for performing real time streaming project leveraging retail sales data and to perform end to end solutions, Thanks

**Project Details:**

In this project, I have used sample retail csv data sets for my hands-on into Confluent Cloud Kafka, Please find step by step details below:
1. Creation of the account in the Confluent Cloud Application : https://www.confluent.io/confluent-cloud/
2. Register API keys for Cluster
3. Create Topic
4. Create Data Contract for the Data/Value, Schema Registry and generate API key
5. Create Python Producer and Consumer Code by implementing the required keys, topic name, subject name, producer and consumer related strategies
6. Run Producer Python Code from Local VS code and check the messages in the corresponding Topics in the Confluent Cloud UI
7. Validate the data to see if there is any issues and check for sample data in all the paritions mentioned in the Producer code
8. Once Data looks good, Run the Consumer code with required settings for groupid and offset type
9. Once Consumer Code ran successfully, Please check the Confluent Cloud UI to make sure consumer ran successfully
10. Please terminate the running Producer and Consumer Python Code in the VS code
11. Please make sure to install required Python libraries and packages before running the Producer and Consumer Code from local VS code
    
